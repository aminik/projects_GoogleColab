{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUdpOw5QZR+pqM4/i6HOwg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminik/projects_GoogleColab/blob/main/model_nn_transaction_netron_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Использование CPU и GPU на примере простой НС - Нейросети на PyTorch"
      ],
      "metadata": {
        "id": "Fs5zYtY8tdqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls sample_data/*.csv\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWC3BpZAuYjL",
        "outputId": "308a3210-9aa0-404e-8c3a-7af324cc5394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data/california_housing_test.csv   sample_data/mnist_test.csv\n",
            "sample_data/california_housing_train.csv  sample_data/mnist_train_small.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Xtwm_iTxwUXu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_iris()\n",
        "X = data['data']\n",
        "y = data['target']\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)# split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)"
      ],
      "metadata": {
        "id": "MP3uU_F90M4Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisModel(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.hidden = nn.Linear(4, 8)\n",
        "\t\tself.act = nn.ReLU()\n",
        "\t\tself.output = nn.Linear(8, 3)\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.act(self.hidden(x))\n",
        "\t\tx = self.output(x)\n",
        "\t\treturn x"
      ],
      "metadata": {
        "id": "5rcav9500Rvh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss metric and optimizer\n",
        "model = IrisModel()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# prepare model and training parameters\n",
        "n_epochs = 100\n",
        "batch_size = 10\n",
        "batch_start = torch.arange(0, len(X_train), batch_size)"
      ],
      "metadata": {
        "id": "KAlj8MpY0Uhl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for epoch in range(n_epochs):\n",
        "\tfor start in batch_start:        # take a batch\n",
        "\t\tX_batch = X_train[start:start+batch_size]\n",
        "\t\ty_batch = y_train[start:start+batch_size]\n",
        "\t\t# forward pass\n",
        "\t\ty_pred = model(X_batch)\n",
        "\t\tloss = loss_fn(y_pred, y_batch)\n",
        "\t\t# backward pass\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\t# update weights\n",
        "\t\toptimizer.step()"
      ],
      "metadata": {
        "id": "4KxdtnXA0XXV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mGcpFf00plL",
        "outputId": "6e931a11-7c3c-493c-a353-4490c7a9671a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.25.5)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validating \t\tmodel\n",
        "y_pred = model(X_test)\n",
        "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
        "acc = float(acc)*100\n",
        "print(\"Model accuracy: %.2f%%\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQqp1dOt0Y8V",
        "outputId": "a646d75b-22bf-46cb-99f9-33e90c6a035b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.onnx.export(model, X_test, 'iris.onnx', input_names=[\"features\"], output_names=[\"logits\"])"
      ],
      "metadata": {
        "id": "zrScfGpO0fVD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Выполнение этой функции создаст файл iris.onnx в локальном каталоге. Вам необходимо предоставить пример тензора, который работает с моделью в качестве входных данных (X_test в приведенном выше примере).\n",
        "\n",
        "Это необходимо потому, что во время преобразования необходимо следовать этому примеру тензора, чтобы понять, какие операции должны быть применены, чтобы вы могли преобразовать алгоритм шаг за шагом в формат ONNX.\n",
        "\n",
        "Каждый вес в модели PyTorch является тензором, и им присвоено имя. Но входные и выходные тензоры обычно не имеют имен, поэтому вам необходимо задать им имя при выполнении функции export(). Эти имена быть представлены в виде списка строк, поскольку в общем случае модель может принимать несколько тензоров и возвращать несколько тензоров.\n",
        "\n",
        "Обычно функцию export() следует запускать после цикла обучения. Это связано с тем, что созданная модель ONNX содержит полную модель, которую можно запустить без библиотеки PyTorch. Вы хотите сохранить оптимизированный вес в ней. Однако для целей визуализации модели в Netron качество модели не имеет значения. Вы можете вызвать функцию export(), как только модель PyTorch будет создана."
      ],
      "metadata": {
        "id": "lxkzNYYePyMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ah\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy-mvxGNPcl8",
        "outputId": "c3e8f6e8-1a22-4f59-90ee-a18b46a3c923"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  .config\tiris.onnx  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netron"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vVo2d9-P2ZF",
        "outputId": "fa5435b6-22d2-4d5a-e228-2af5222edd77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netron\n",
            "  Downloading netron-8.1.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Downloading netron-8.1.4-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: netron\n",
            "Successfully installed netron-8.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3HPLGttP4Qk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}